import { d, b, c } from './chunk-VO7VPLVP.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';

var oe={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},ae={stop:void 0},ie={blob:void 0,text:void 0},pe=L=>{let{apiKey:g,autoStart:x,autoTranscribe:U,mode:T,nonStop:P,removeSilence:M,stopTimeout:O,streaming:k,timeSlice:q,whisperConfig:u,onDataAvailable:K,onTranscribe:d$1}={...oe,...L};if(!g&&!d$1)throw new Error("apiKey is required if onTranscribe is not provided");let l=useRef([]),i=useRef(),s=useRef(),t=useRef(),a=useRef(),m=useRef(ae),[I,R]=useState(!1),[$,B]=useState(!1),b$1=useRef(!1),[j,w]=useState(!1),[z,f]=useState(ie);useEffect(()=>()=>{l.current&&(l.current=[]),i.current&&(i.current.flush(),i.current=void 0),t.current&&(t.current.destroy(),t.current=void 0),y("stop"),s.current&&(s.current.off("speaking",v),s.current.off("stopped_speaking",A)),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},[]),useEffectAsync(async()=>{x&&await C();},[x]);let N=async()=>{await C();},G=async()=>{await X();},J=async()=>{await W();},C=async()=>{try{if(a.current||await Q(),a.current){if(!t.current){let{default:{RecordRTCPromisesHandler:r,StereoAudioRecorder:o}}=await import('recordrtc'),n={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:o,sampleRate:44100,timeSlice:k?q:void 0,type:"audio",ondataavailable:U&&k?ee:void 0};t.current=new r(a.current,n);}if(!i.current){let{Mp3Encoder:r}=await import('lamejs');i.current=new r(1,44100,96);}let e=await t.current.getState();(e==="inactive"||e==="stopped")&&await t.current.startRecording(),e==="paused"&&await t.current.resumeRecording(),R(!0);}}catch{}},Q=async()=>{try{if(a.current&&a.current.getTracks().forEach(e=>e.stop()),a.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!s.current){let{default:e}=await import('hark');s.current=e(a.current,{interval:100,play:!1}),s.current.on("speaking",v),s.current.on("stopped_speaking",A);}}catch{}},V=e=>{m.current[e]||(m.current[e]=setTimeout(W,O));},v=()=>{B(!0),b$1.current=!0,y("stop");},A=()=>{B(!1),P&&b$1.current&&V("stop");},X=async()=>{try{t.current&&(await t.current.getState()==="recording"&&await t.current.pauseRecording(),y("stop"),R(!1));}catch{}},W=async()=>{try{if(t.current){let e=await t.current.getState();if((e==="recording"||e==="paused")&&await t.current.stopRecording(),Y(),y("stop"),R(!1),b$1.current=!1,U)await Z();else {let r=await t.current.getBlob();f({blob:r});}await t.current.destroy(),l.current=[],i.current&&(i.current.flush(),i.current=void 0),t.current=void 0;}}catch{}},Y=()=>{s.current&&(s.current.off("speaking",v),s.current.off("stopped_speaking",A),s.current=void 0),a.current&&(a.current.getTracks().forEach(e=>e.stop()),a.current=void 0);},y=e=>{m.current[e]&&(clearTimeout(m.current[e]),m.current[e]=void 0);},Z=async()=>{try{if(i.current&&t.current&&await t.current.getState()==="stopped"){w(!0);let r=await t.current.getBlob();if(M){let{createFFmpeg:o}=await import('@ffmpeg/ffmpeg'),n=o({mainName:"main",corePath:b,log:!0});n.isLoaded()||await n.load();let c$1=await r.arrayBuffer();n.FS("writeFile","in.wav",new Uint8Array(c$1)),await n.run("-i","in.wav","-acodec","libmp3lame","-b:a","96k","-ar","44100","-af",c,"out.mp3");let h=n.FS("readFile","out.mp3");if(h.length<=225){n.exit(),f({blob:r}),w(!1);return}r=new Blob([h.buffer],{type:"audio/mpeg"}),n.exit();}else {let o=await r.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o));r=new Blob([n],{type:"audio/mpeg"});}if(typeof d$1=="function"){let o=await d$1(r);f(o);}else {let o=new File([r],"speech.mp3",{type:"audio/mpeg"}),n=await E(o);f({blob:r,text:n});}w(!1);}}catch{w(!1);}},ee=async e=>{try{if(k&&t.current){if(K?.(e),i.current){let o=await e.arrayBuffer(),n=i.current.encodeBuffer(new Int16Array(o)),c=new Blob([n],{type:"audio/mpeg"});l.current.push(c);}if(await t.current.getState()==="recording"){let o=new Blob(l.current,{type:"audio/mpeg"});if(typeof d$1=="function"){let n=await d$1(o);n.text&&f(c=>({...c,text:n.text}));}else {let n=new File([o],"speech.mp3",{type:"audio/mpeg"}),c=await E(n);c&&f(h=>({...h,text:c}));}}}}catch{}},E=useMemoAsync(async e=>{let r=new FormData;r.append("file",e),r.append("model","whisper-1"),T==="transcriptions"&&r.append("language",u?.language??"en"),u?.prompt&&r.append("prompt",u.prompt),u?.response_format&&r.append("response_format",u.response_format),u?.temperature&&r.append("temperature",`${u.temperature}`);let o={};o["Content-Type"]="multipart/form-data",g&&(o.Authorization=`Bearer ${g}`);let{default:n}=await import('axios');return (await n.post(d+T,r,{headers:o})).data.text},[g,T,u]);return {recording:I,speaking:$,spokeAtLeastOnce:b$1,transcribing:j,transcript:z,pauseRecording:G,startRecording:N,stopRecording:J}};

export { pe as a };
