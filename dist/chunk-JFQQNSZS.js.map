{"version":3,"sources":["../src/useWhisper.ts"],"names":["useEffectAsync","useMemoAsync","useEffect","useRef","useState","defaultConfig","defaultTimeout","defaultTranscript","useWhisper","config","apiKey","autoStart","autoTranscribe","mode","nonStop","removeSilence","stopTimeout","streaming","timeSlice","whisperConfig","onDataAvailableCallback","onTranscribeCallback","chunks","encoder","listener","recorder","stream","timeout","recording","setRecording","speaking","setSpeaking","spokeAtLeastOnce","transcribing","setTranscribing","transcript","setTranscript","audioContext","onStopTimeout","onStartSpeaking","onStopSpeaking","track","onStartRecording","startRecording","pauseRecording","onPauseRecording","stopRecording","onStopRecording","onStartStreaming","RecordRTCPromisesHandler","StereoAudioRecorder","recorderConfig","onDataAvailable","Mp3Encoder","recordState","hark","onStartTimeout","type","onStopStreaming","onTranscribing","blob","buffer","mp3","transcribed","file","text","onWhispered","data","mp3chunk","mp3blob","prev","body","headers","axios","whisperApiEndpoint"],"mappings":"+CAAA,OAAS,kBAAAA,EAAgB,gBAAAC,MAAoB,kCAI7C,OAAS,aAAAC,GAAW,UAAAC,EAAQ,YAAAC,MAAgB,QAa5C,IAAMC,GAAkC,CACtC,OAAQ,GACR,UAAW,GACX,eAAgB,GAChB,KAAM,iBACN,QAAS,GACT,cAAe,GACf,YAAa,IACb,UAAW,GACX,UAAW,IACX,gBAAiB,OACjB,aAAc,MAChB,EAKMC,GAAoC,CACxC,KAAM,MACR,EAKMC,GAA0C,CAC9C,KAAM,OACN,KAAM,MACR,EAKaC,GAA8BC,GAAW,CACpD,GAAM,CACJ,OAAAC,EACA,UAAAC,EACA,eAAAC,EACA,KAAAC,EACA,QAAAC,EACA,cAAAC,GACA,YAAAC,EACA,UAAAC,EACA,UAAAC,GACA,cAAAC,EACA,gBAAiBC,EACjB,aAAcC,CAChB,EAAI,CACF,GAAGhB,GACH,GAAGI,CACL,EAEA,GAAI,CAACC,GAAU,CAACW,EACd,MAAM,IAAI,MAAM,oDAAoD,EAGtE,IAAMC,EAASnB,EAAe,CAAC,CAAC,EAC1BoB,EAAUpB,EAAgB,EAC1BqB,EAAWrB,EAAe,EAC1BsB,EAAWtB,EAAiC,EAC5CuB,EAASvB,EAAoB,EAC7BwB,EAAUxB,EAA0BG,EAAc,EAElD,CAACsB,EAAWC,CAAY,EAAIzB,EAAkB,EAAK,EACnD,CAAC0B,EAAUC,CAAW,EAAI3B,EAAkB,EAAK,EACjD4B,EAAmB7B,EAAgB,EAAK,EACxC,CAAC8B,EAAcC,CAAe,EAAI9B,EAAkB,EAAK,EACzD,CAAC+B,EAAYC,CAAa,EAC9BhC,EAA+BG,EAAiB,EAE5C8B,EAAe,IAAI,aAUzBnC,GAAU,IACD,IAAM,CACPoB,EAAO,UACTA,EAAO,QAAU,CAAC,GAEhBC,EAAQ,UACVA,EAAQ,QAAQ,MAAM,EACtBA,EAAQ,QAAU,QAEhBE,EAAS,UACXA,EAAS,QAAQ,QAAQ,EACzBA,EAAS,QAAU,QAErBa,EAAc,MAAM,EAChBd,EAAS,UAEXA,EAAS,QAAQ,IAAI,WAAYe,CAAe,EAEhDf,EAAS,QAAQ,IAAI,mBAAoBgB,CAAc,GAErDd,EAAO,UACTA,EAAO,QAAQ,UAAU,EAAE,QAASe,GAAUA,EAAM,KAAK,CAAC,EAC1Df,EAAO,QAAU,OAErB,EACC,CAAC,CAAC,EAML1B,EAAe,SAAY,CACrBW,GACF,MAAM+B,EAAiB,CAE3B,EAAG,CAAC/B,CAAS,CAAC,EAKd,IAAMgC,EAAiB,SAAY,CACjC,MAAMD,EAAiB,CACzB,EAKME,EAAiB,SAAY,CACjC,MAAMC,EAAiB,CACzB,EAKMC,EAAgB,SAAY,CAChC,MAAMC,EAAgB,CACxB,EAWML,EAAmB,SAAY,CACnC,GAAI,CAIF,GAHKhB,EAAO,SACV,MAAMsB,EAAiB,EAErBtB,EAAO,QAAS,CAClB,GAAI,CAACD,EAAS,QAAS,CACrB,GAAM,CACJ,QAAS,CAAE,yBAAAwB,EAA0B,oBAAAC,CAAoB,CAC3D,EAAI,KAAM,QAAO,WAAW,EACtBC,EAA0B,CAC9B,SAAU,YACV,sBAAuB,EACvB,aAAcD,EACd,WAAYb,EAAa,WACzB,KAAM,QACN,gBACEzB,GAAkBK,EAAYmC,EAAkB,MACpD,EACA3B,EAAS,QAAU,IAAIwB,EACrBvB,EAAO,QACPyB,CACF,EAEF,GAAI,CAAC5B,EAAQ,QAAS,CACpB,GAAM,CAAE,WAAA8B,CAAW,EAAI,KAAM,QAAO,QAAQ,EAC5C9B,EAAQ,QAAU,IAAI8B,EAAW,EAAGhB,EAAa,WAAY,EAAE,EAEjE,IAAMiB,EAAc,MAAM7B,EAAS,QAAQ,SAAS,GAChD6B,IAAgB,YAAcA,IAAgB,YAChD,MAAM7B,EAAS,QAAQ,eAAe,EAEpC6B,IAAgB,UAClB,MAAM7B,EAAS,QAAQ,gBAAgB,EAEzCI,EAAa,EAAI,EAErB,MAAE,CAEF,CACF,EAQMmB,EAAmB,SAAY,CACnC,GAAI,CAOF,GANItB,EAAO,SACTA,EAAO,QAAQ,UAAU,EAAE,QAASe,GAAUA,EAAM,KAAK,CAAC,EAE5Df,EAAO,QAAU,MAAM,UAAU,aAAa,aAAa,CACzD,MAAO,EACT,CAAC,EACG,CAACF,EAAS,QAAS,CACrB,GAAM,CAAE,QAAS+B,CAAK,EAAI,KAAM,QAAO,MAAM,EAC7C/B,EAAS,QAAU+B,EAAK7B,EAAO,QAAS,CACtC,SAAU,IACV,KAAM,EACR,CAAC,EACDF,EAAS,QAAQ,GAAG,WAAYe,CAAe,EAC/Cf,EAAS,QAAQ,GAAG,mBAAoBgB,CAAc,EAE1D,MAAE,CAEF,CACF,EAKMgB,EAAkBC,GAAkC,CACnD9B,EAAQ,QAAQ8B,CAAI,IACvB9B,EAAQ,QAAQ8B,CAAI,EAAI,WAAWV,EAAiB/B,CAAW,EAEnE,EAOMuB,EAAkB,IAAM,CAE5BR,EAAY,EAAI,EAChBC,EAAiB,QAAU,GAC3BM,EAAc,MAAM,CACtB,EAOME,EAAiB,IAAM,CAE3BT,EAAY,EAAK,EACbjB,GAAWkB,EAAiB,SAC9BwB,EAAe,MAAM,CAEzB,EAQMX,EAAmB,SAAY,CACnC,GAAI,CACEpB,EAAS,UACS,MAAMA,EAAS,QAAQ,SAAS,IAChC,aAClB,MAAMA,EAAS,QAAQ,eAAe,EAExCa,EAAc,MAAM,EACpBT,EAAa,EAAK,EAEtB,MAAE,CAEF,CACF,EAYMkB,EAAkB,SAAY,CAClC,GAAI,CACF,GAAItB,EAAS,QAAS,CACpB,IAAM6B,EAAc,MAAM7B,EAAS,QAAQ,SAAS,EAQpD,IAPI6B,IAAgB,aAAeA,IAAgB,WACjD,MAAM7B,EAAS,QAAQ,cAAc,EAEvCiC,EAAgB,EAChBpB,EAAc,MAAM,EACpBT,EAAa,EAAK,EAClBG,EAAiB,QAAU,GACvBpB,EACF,MAAM+C,EAAe,MAChB,CACL,IAAMC,EAAO,MAAMnC,EAAS,QAAQ,QAAQ,EAC5CW,EAAc,CACZ,KAAAwB,CACF,CAAC,EAEH,MAAMnC,EAAS,QAAQ,QAAQ,EAC/BH,EAAO,QAAU,CAAC,EACdC,EAAQ,UACVA,EAAQ,QAAQ,MAAM,EACtBA,EAAQ,QAAU,QAEpBE,EAAS,QAAU,OAEvB,MAAE,CAEF,CACF,EAQMiC,EAAkB,IAAM,CACxBlC,EAAS,UAGXO,EAAY,EAAK,EAEjBP,EAAS,QAAQ,IAAI,WAAYe,CAAe,EAEhDf,EAAS,QAAQ,IAAI,mBAAoBgB,CAAc,EACvDhB,EAAS,QAAU,QAEjBE,EAAO,UACTA,EAAO,QAAQ,UAAU,EAAE,QAASe,GAAUA,EAAM,KAAK,CAAC,EAC1Df,EAAO,QAAU,OAErB,EAMMY,EAAiBmB,GAAkC,CACnD9B,EAAQ,QAAQ8B,CAAI,IACtB,aAAa9B,EAAQ,QAAQ8B,CAAI,CAAC,EAClC9B,EAAQ,QAAQ8B,CAAI,EAAI,OAE5B,EAaME,EAAiB,SAAY,CAEjC,GAAI,CACF,GAAIpC,EAAQ,SAAWE,EAAS,SACV,MAAMA,EAAS,QAAQ,SAAS,IAChC,UAAW,CAC7BS,EAAgB,EAAI,EACpB,IAAI0B,EAAO,MAAMnC,EAAS,QAAQ,QAAQ,EACpCoC,EAAS,MAAMD,EAAK,YAAY,EAEhCE,EAAMvC,EAAQ,QAAQ,aAAa,IAAI,WAAWsC,CAAM,CAAC,EAI/D,GAHAD,EAAO,IAAI,KAAK,CAACE,CAAG,EAAG,CAAE,KAAM,YAAa,CAAC,EAGzC,OAAOzC,GAAyB,WAAY,CAC9C,IAAM0C,EAAc,MAAM1C,EAAqBuC,CAAI,EAEnDxB,EAAc2B,CAAW,MACpB,CACL,IAAMC,EAAO,IAAI,KAAK,CAACJ,CAAI,EAAG,aAAc,CAAE,KAAM,YAAa,CAAC,EAC5DK,EAAO,MAAMC,EAAYF,CAAI,EAEnC5B,EAAc,CACZ,KAAAwB,EACA,KAAAK,CACF,CAAC,EAEH/B,EAAgB,EAAK,EAG3B,MAAE,CAEAA,EAAgB,EAAK,CACvB,CACF,EAQMkB,EAAkB,MAAOe,GAAe,CAE5C,GAAI,CACF,GAAIlD,GAAaQ,EAAS,QAAS,CAEjC,GADAL,IAA0B+C,CAAI,EAC1B5C,EAAQ,QAAS,CACnB,IAAMsC,EAAS,MAAMM,EAAK,YAAY,EAChCC,EAAW7C,EAAQ,QAAQ,aAAa,IAAI,WAAWsC,CAAM,CAAC,EAC9DQ,EAAU,IAAI,KAAK,CAACD,CAAQ,EAAG,CAAE,KAAM,YAAa,CAAC,EAC3D9C,EAAO,QAAQ,KAAK+C,CAAO,EAG7B,GADsB,MAAM5C,EAAS,QAAQ,SAAS,IAChC,YAAa,CACjC,IAAMmC,EAAO,IAAI,KAAKtC,EAAO,QAAS,CACpC,KAAM,YACR,CAAC,EACD,GAAI,OAAOD,GAAyB,WAAY,CAC9C,IAAM0C,EAAc,MAAM1C,EAAqBuC,CAAI,EAG/CG,EAAY,MACd3B,EAAekC,IAAU,CAAE,GAAGA,EAAM,KAAMP,EAAY,IAAK,EAAE,MAE1D,CACL,IAAMC,EAAO,IAAI,KAAK,CAACJ,CAAI,EAAG,aAAc,CAC1C,KAAM,YACR,CAAC,EAEKK,EAAO,MAAMC,EAAYF,CAAI,EAG/BC,GACF7B,EAAekC,IAAU,CAAE,GAAGA,EAAM,KAAAL,CAAK,EAAE,IAKrD,MAAE,CAEF,CACF,EAUMC,EAAcjE,EAClB,MAAO+D,GAAe,CAEpB,IAAMO,EAAO,IAAI,SACjBA,EAAK,OAAO,OAAQP,CAAI,EACxBO,EAAK,OAAO,QAAS,WAAW,EAC5B1D,IAAS,kBACX0D,EAAK,OAAO,WAAYpD,GAAe,UAAY,IAAI,EAErDA,GAAe,QACjBoD,EAAK,OAAO,SAAUpD,EAAc,MAAM,EAExCA,GAAe,iBACjBoD,EAAK,OAAO,kBAAmBpD,EAAc,eAAe,EAE1DA,GAAe,aACjBoD,EAAK,OAAO,cAAe,GAAGpD,EAAc,aAAa,EAE3D,IAAMqD,EAAkC,CAAC,EACzCA,EAAQ,cAAc,EAAI,sBACtB9D,IACF8D,EAAQ,cAAmB,UAAU9D,KAEvC,GAAM,CAAE,QAAS+D,CAAM,EAAI,KAAM,QAAO,OAAO,EAI/C,OAHiB,MAAMA,EAAM,KAAKC,EAAqB7D,EAAM0D,EAAM,CACjE,QAAAC,CACF,CAAC,GACe,KAAK,IACvB,EACA,CAAC9D,EAAQG,EAAMM,CAAa,CAC9B,EAEA,MAAO,CACL,UAAAS,EACA,SAAAE,EACA,iBAAAE,EACA,aAAAC,EACA,WAAAE,EACA,eAAAS,EACA,eAAAD,EACA,cAAAG,CACF,CACF","sourcesContent":["import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async'\nimport type { RawAxiosRequestHeaders } from 'axios'\nimport type { Harker } from 'hark'\nimport type { Encoder } from 'lamejs'\nimport { useEffect, useRef, useState } from 'react'\nimport type { Options, RecordRTCPromisesHandler } from 'recordrtc'\nimport { defaultStopTimeout, whisperApiEndpoint } from './configs'\nimport {\n  UseWhisperConfig,\n  UseWhisperHook,\n  UseWhisperTimeout,\n  UseWhisperTranscript,\n} from './types'\n\n/**\n * default useWhisper configuration\n */\nconst defaultConfig: UseWhisperConfig = {\n  apiKey: '',\n  autoStart: false,\n  autoTranscribe: true,\n  mode: 'transcriptions',\n  nonStop: false,\n  removeSilence: false,\n  stopTimeout: defaultStopTimeout,\n  streaming: false,\n  timeSlice: 1_000,\n  onDataAvailable: undefined,\n  onTranscribe: undefined,\n}\n\n/**\n * default timeout for recorder\n */\nconst defaultTimeout: UseWhisperTimeout = {\n  stop: undefined,\n}\n\n/**\n * default transcript object\n */\nconst defaultTranscript: UseWhisperTranscript = {\n  blob: undefined,\n  text: undefined,\n}\n\n/**\n * React Hook for OpenAI Whisper\n */\nexport const useWhisper: UseWhisperHook = (config) => {\n  const {\n    apiKey,\n    autoStart,\n    autoTranscribe,\n    mode,\n    nonStop,\n    removeSilence,\n    stopTimeout,\n    streaming,\n    timeSlice,\n    whisperConfig,\n    onDataAvailable: onDataAvailableCallback,\n    onTranscribe: onTranscribeCallback,\n  } = {\n    ...defaultConfig,\n    ...config,\n  }\n\n  if (!apiKey && !onTranscribeCallback) {\n    throw new Error('apiKey is required if onTranscribe is not provided')\n  }\n\n  const chunks = useRef<Blob[]>([])\n  const encoder = useRef<Encoder>()\n  const listener = useRef<Harker>()\n  const recorder = useRef<RecordRTCPromisesHandler>()\n  const stream = useRef<MediaStream>()\n  const timeout = useRef<UseWhisperTimeout>(defaultTimeout)\n\n  const [recording, setRecording] = useState<boolean>(false)\n  const [speaking, setSpeaking] = useState<boolean>(false)\n  const spokeAtLeastOnce = useRef<boolean>(false)\n  const [transcribing, setTranscribing] = useState<boolean>(false)\n  const [transcript, setTranscript] =\n    useState<UseWhisperTranscript>(defaultTranscript)\n\n  const audioContext = new AudioContext()\n\n  /**\n   * cleanup on component unmounted\n   * - flush out and cleanup lamejs encoder instance\n   * - destroy recordrtc instance and clear it from ref\n   * - clear setTimout for onStopRecording\n   * - clean up hark speaking detection listeners and clear it from ref\n   * - stop all user's media steaming track and remove it from ref\n   */\n  useEffect(() => {\n    return () => {\n      if (chunks.current) {\n        chunks.current = []\n      }\n      if (encoder.current) {\n        encoder.current.flush()\n        encoder.current = undefined\n      }\n      if (recorder.current) {\n        recorder.current.destroy()\n        recorder.current = undefined\n      }\n      onStopTimeout('stop')\n      if (listener.current) {\n        // @ts-ignore\n        listener.current.off('speaking', onStartSpeaking)\n        // @ts-ignore\n        listener.current.off('stopped_speaking', onStopSpeaking)\n      }\n      if (stream.current) {\n        stream.current.getTracks().forEach((track) => track.stop())\n        stream.current = undefined\n      }\n    }\n  }, [])\n\n  /**\n   * if config.autoStart is true\n   * start speech recording immediately upon component mounted\n   */\n  useEffectAsync(async () => {\n    if (autoStart) {\n      await onStartRecording()\n    }\n  }, [autoStart])\n\n  /**\n   * start speech recording and start listen for speaking event\n   */\n  const startRecording = async () => {\n    await onStartRecording()\n  }\n\n  /**\n   * pause speech recording also stop media stream\n   */\n  const pauseRecording = async () => {\n    await onPauseRecording()\n  }\n\n  /**\n   * stop speech recording and start the transcription\n   */\n  const stopRecording = async () => {\n    await onStopRecording()\n  }\n\n  /**\n   * start speech recording event\n   * - first ask user for media stream\n   * - create recordrtc instance and pass media stream to it\n   * - create lamejs encoder instance\n   * - check recorder state and start or resume recorder accordingly\n   * - start timeout for stop timeout config\n   * - update recording state to true\n   */\n  const onStartRecording = async () => {\n    try {\n      if (!stream.current) {\n        await onStartStreaming()\n      }\n      if (stream.current) {\n        if (!recorder.current) {\n          const {\n            default: { RecordRTCPromisesHandler, StereoAudioRecorder },\n          } = await import('recordrtc')\n          const recorderConfig: Options = {\n            mimeType: 'audio/wav',\n            numberOfAudioChannels: 1, // mono\n            recorderType: StereoAudioRecorder,\n            sampleRate: audioContext.sampleRate,\n            type: 'audio',\n            ondataavailable:\n              autoTranscribe && streaming ? onDataAvailable : undefined,\n          }\n          recorder.current = new RecordRTCPromisesHandler(\n            stream.current,\n            recorderConfig\n          )\n        }\n        if (!encoder.current) {\n          const { Mp3Encoder } = await import('lamejs')\n          encoder.current = new Mp3Encoder(1, audioContext.sampleRate, 96)\n        }\n        const recordState = await recorder.current.getState()\n        if (recordState === 'inactive' || recordState === 'stopped') {\n          await recorder.current.startRecording()\n        }\n        if (recordState === 'paused') {\n          await recorder.current.resumeRecording()\n        }\n        setRecording(true)\n      }\n    } catch (err) {\n      console.error(err)\n    }\n  }\n\n  /**\n   * get user media stream event\n   * - try to stop all previous media streams\n   * - ask user for media stream with a system popup\n   * - register hark speaking detection listeners\n   */\n  const onStartStreaming = async () => {\n    try {\n      if (stream.current) {\n        stream.current.getTracks().forEach((track) => track.stop())\n      }\n      stream.current = await navigator.mediaDevices.getUserMedia({\n        audio: true,\n      })\n      if (!listener.current) {\n        const { default: hark } = await import('hark')\n        listener.current = hark(stream.current, {\n          interval: 100,\n          play: false,\n        })\n        listener.current.on('speaking', onStartSpeaking)\n        listener.current.on('stopped_speaking', onStopSpeaking)\n      }\n    } catch (err) {\n      console.error(err)\n    }\n  }\n\n  /**\n   * start stop timeout event\n   */\n  const onStartTimeout = (type: keyof UseWhisperTimeout) => {\n    if (!timeout.current[type]) {\n      timeout.current[type] = setTimeout(onStopRecording, stopTimeout)\n    }\n  }\n\n  /**\n   * user start speaking event\n   * - set speaking state to true\n   * - clear stop timeout\n   */\n  const onStartSpeaking = () => {\n    console.log('start speaking')\n    setSpeaking(true)\n    spokeAtLeastOnce.current = true\n    onStopTimeout('stop')\n  }\n\n  /**\n   * user stop speaking event\n   * - set speaking state to false\n   * - start stop timeout back\n   */\n  const onStopSpeaking = () => {\n    console.log('stop speaking')\n    setSpeaking(false)\n    if (nonStop && spokeAtLeastOnce.current) {\n      onStartTimeout('stop')\n    }\n  }\n\n  /**\n   * pause speech recording event\n   * - if recorder state is recording, pause the recorder\n   * - clear stop timeout\n   * - set recoriding state to false\n   */\n  const onPauseRecording = async () => {\n    try {\n      if (recorder.current) {\n        const recordState = await recorder.current.getState()\n        if (recordState === 'recording') {\n          await recorder.current.pauseRecording()\n        }\n        onStopTimeout('stop')\n        setRecording(false)\n      }\n    } catch (err) {\n      console.error(err)\n    }\n  }\n\n  /**\n   * stop speech recording event\n   * - flush out lamejs encoder and set it to undefined\n   * - if recorder state is recording or paused, stop the recorder\n   * - stop user media stream\n   * - clear stop timeout\n   * - set recording state to false\n   * - start Whisper transcription event\n   * - destroy recordrtc instance and clear it from ref\n   */\n  const onStopRecording = async () => {\n    try {\n      if (recorder.current) {\n        const recordState = await recorder.current.getState()\n        if (recordState === 'recording' || recordState === 'paused') {\n          await recorder.current.stopRecording()\n        }\n        onStopStreaming()\n        onStopTimeout('stop')\n        setRecording(false)\n        spokeAtLeastOnce.current = false\n        if (autoTranscribe) {\n          await onTranscribing()\n        } else {\n          const blob = await recorder.current.getBlob()\n          setTranscript({\n            blob,\n          })\n        }\n        await recorder.current.destroy()\n        chunks.current = []\n        if (encoder.current) {\n          encoder.current.flush()\n          encoder.current = undefined\n        }\n        recorder.current = undefined\n      }\n    } catch (err) {\n      console.error(err)\n    }\n  }\n\n  /**\n   * stop media stream event\n   * - remove hark speaking detection listeners\n   * - stop all media stream tracks\n   * - clear media stream from ref\n   */\n  const onStopStreaming = () => {\n    if (listener.current) {\n      // If hark doesn't get the chance to trigger the stop event before streaming is stopped\n      // the speaking state doesn't reset and remains true\n      setSpeaking(false)\n      // @ts-ignore\n      listener.current.off('speaking', onStartSpeaking)\n      // @ts-ignore\n      listener.current.off('stopped_speaking', onStopSpeaking)\n      listener.current = undefined\n    }\n    if (stream.current) {\n      stream.current.getTracks().forEach((track) => track.stop())\n      stream.current = undefined\n    }\n  }\n\n  /**\n   * stop timeout event\n   * - clear stop timeout and remove it from ref\n   */\n  const onStopTimeout = (type: keyof UseWhisperTimeout) => {\n    if (timeout.current[type]) {\n      clearTimeout(timeout.current[type])\n      timeout.current[type] = undefined\n    }\n  }\n\n  /**\n   * start Whisper transcrition event\n   * - make sure recorder state is stopped\n   * - set transcribing state to true\n   * - get audio blob from recordrtc\n   * - if config.removeSilence is true, load ffmpeg-wasp and try to remove silence from speec\n   * - if config.customServer is true, send audio data to custom server in base64 string\n   * - if config.customServer is false, send audio data to Whisper api in multipart/form-data\n   * - set transcript object with audio blob and transcription result from Whisper\n   * - set transcribing state to false\n   */\n  const onTranscribing = async () => {\n    console.log('transcribing speech')\n    try {\n      if (encoder.current && recorder.current) {\n        const recordState = await recorder.current.getState()\n        if (recordState === 'stopped') {\n          setTranscribing(true)\n          let blob = await recorder.current.getBlob()\n          const buffer = await blob.arrayBuffer()\n          console.log({ wav: buffer.byteLength })\n          const mp3 = encoder.current.encodeBuffer(new Int16Array(buffer))\n          blob = new Blob([mp3], { type: 'audio/mpeg' })\n          console.log({ blob, mp3: mp3.byteLength })\n\n          if (typeof onTranscribeCallback === 'function') {\n            const transcribed = await onTranscribeCallback(blob)\n            console.log('onTranscribe', transcribed)\n            setTranscript(transcribed)\n          } else {\n            const file = new File([blob], 'speech.mp3', { type: 'audio/mpeg' })\n            const text = await onWhispered(file)\n            console.log('onTranscribing', { text })\n            setTranscript({\n              blob,\n              text,\n            })\n          }\n          setTranscribing(false)\n        }\n      }\n    } catch (err) {\n      console.info(err)\n      setTranscribing(false)\n    }\n  }\n\n  /**\n   * Get audio data in chunk based on timeSlice\n   * - while recording send audio chunk to Whisper\n   * - chunks are concatenated in succession\n   * - set transcript text with interim result\n   */\n  const onDataAvailable = async (data: Blob) => {\n    console.log('onDataAvailable', data)\n    try {\n      if (streaming && recorder.current) {\n        onDataAvailableCallback?.(data)\n        if (encoder.current) {\n          const buffer = await data.arrayBuffer()\n          const mp3chunk = encoder.current.encodeBuffer(new Int16Array(buffer))\n          const mp3blob = new Blob([mp3chunk], { type: 'audio/mpeg' })\n          chunks.current.push(mp3blob)\n        }\n        const recorderState = await recorder.current.getState()\n        if (recorderState === 'recording') {\n          const blob = new Blob(chunks.current, {\n            type: 'audio/mpeg',\n          })\n          if (typeof onTranscribeCallback === 'function') {\n            const transcribed = await onTranscribeCallback(blob)\n            console.log('onTranscribe', transcribed)\n\n            if (transcribed.text) {\n              setTranscript((prev) => ({ ...prev, text: transcribed.text }))\n            }\n          } else {\n            const file = new File([blob], 'speech.mp3', {\n              type: 'audio/mpeg',\n            })\n\n            const text = await onWhispered(file)\n            console.log('onTranscribing', { text })\n\n            if (text) {\n              setTranscript((prev) => ({ ...prev, text }))\n            }\n          }\n        }\n      }\n    } catch (err) {\n      console.error(err)\n    }\n  }\n\n  /**\n   * Send audio file to Whisper to be transcribed\n   * - create formdata and append file, model, and language\n   * - append more Whisper config if whisperConfig is provided\n   * - add OpenAPI Token to header Authorization Bearer\n   * - post with axios to OpenAI Whisper transcript endpoint\n   * - return transcribed text result\n   */\n  const onWhispered = useMemoAsync(\n    async (file: File) => {\n      // Whisper only accept multipart/form-data currently\n      const body = new FormData()\n      body.append('file', file)\n      body.append('model', 'whisper-1')\n      if (mode === 'transcriptions') {\n        body.append('language', whisperConfig?.language ?? 'en')\n      }\n      if (whisperConfig?.prompt) {\n        body.append('prompt', whisperConfig.prompt)\n      }\n      if (whisperConfig?.response_format) {\n        body.append('response_format', whisperConfig.response_format)\n      }\n      if (whisperConfig?.temperature) {\n        body.append('temperature', `${whisperConfig.temperature}`)\n      }\n      const headers: RawAxiosRequestHeaders = {}\n      headers['Content-Type'] = 'multipart/form-data'\n      if (apiKey) {\n        headers['Authorization'] = `Bearer ${apiKey}`\n      }\n      const { default: axios } = await import('axios')\n      const response = await axios.post(whisperApiEndpoint + mode, body, {\n        headers,\n      })\n      return response.data.text\n    },\n    [apiKey, mode, whisperConfig]\n  )\n\n  return {\n    recording,\n    speaking,\n    spokeAtLeastOnce,\n    transcribing,\n    transcript,\n    pauseRecording,\n    startRecording,\n    stopRecording,\n  }\n}\n"]}