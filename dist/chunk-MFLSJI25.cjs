'use strict';

var chunkMMJMXXC7_cjs = require('./chunk-MMJMXXC7.cjs');
var reactHooksAsync = require('@chengsokdara/react-hooks-async');
var react = require('react');

var re={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},te={stop:void 0},ne={blob:void 0,text:void 0},ue=F=>{let{apiKey:g,autoStart:v,autoTranscribe:C,mode:h,nonStop:M,removeSilence:oe,stopTimeout:O,streaming:W,timeSlice:ae,whisperConfig:u,onDataAvailable:P,onTranscribe:f}={...re,...F};if(!g&&!f)throw new Error("apiKey is required if onTranscribe is not provided");let d=react.useRef([]),o=react.useRef(),i=react.useRef(),r=react.useRef(),n=react.useRef(),l=react.useRef(te),[q,T]=react.useState(!1),[K,S]=react.useState(!1),b=react.useRef(!1),[L,k]=react.useState(!1),[I,m]=react.useState(ne),U=new AudioContext;react.useEffect(()=>()=>{d.current&&(d.current=[]),o.current&&(o.current.flush(),o.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),w("stop"),i.current&&(i.current.off("speaking",R),i.current.off("stopped_speaking",A)),n.current&&(n.current.getTracks().forEach(e=>e.stop()),n.current=void 0);},[]),reactHooksAsync.useEffectAsync(async()=>{v&&await B();},[v]);let $=async()=>{await B();},j=async()=>{await N();},z=async()=>{await E();},B=async()=>{try{if(n.current||await G(),n.current){if(!r.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:a}}=await import('recordrtc'),s={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:a,sampleRate:U.sampleRate,type:"audio",ondataavailable:C&&W?X:void 0};r.current=new t(n.current,s);}if(!o.current){let{Mp3Encoder:t}=await import('lamejs');o.current=new t(1,U.sampleRate,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),T(!0);}}catch{}},G=async()=>{try{if(n.current&&n.current.getTracks().forEach(e=>e.stop()),n.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!i.current){let{default:e}=await import('hark');i.current=e(n.current,{interval:100,play:!1}),i.current.on("speaking",R),i.current.on("stopped_speaking",A);}}catch{}},J=e=>{l.current[e]||(l.current[e]=setTimeout(E,O));},R=()=>{S(!0),b.current=!0,w("stop");},A=()=>{S(!1),M&&b.current&&J("stop");},N=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),w("stop"),T(!1));}catch{}},E=async()=>{try{if(r.current){let e=await r.current.getState();if((e==="recording"||e==="paused")&&await r.current.stopRecording(),Q(),w("stop"),T(!1),b.current=!1,C)await V();else {let t=await r.current.getBlob();m({blob:t});}await r.current.destroy(),d.current=[],o.current&&(o.current.flush(),o.current=void 0),r.current=void 0;}}catch{}},Q=()=>{i.current&&(S(!1),i.current.off("speaking",R),i.current.off("stopped_speaking",A),i.current=void 0),n.current&&(n.current.getTracks().forEach(e=>e.stop()),n.current=void 0);},w=e=>{l.current[e]&&(clearTimeout(l.current[e]),l.current[e]=void 0);},V=async()=>{try{if(o.current&&r.current&&await r.current.getState()==="stopped"){k(!0);let t=await r.current.getBlob(),a=await t.arrayBuffer(),s=o.current.encodeBuffer(new Int16Array(a));if(t=new Blob([s],{type:"audio/mpeg"}),typeof f=="function"){let c=await f(t);m(c);}else {let c=new File([t],"speech.mp3",{type:"audio/mpeg"}),x=await H(c);m({blob:t,text:x});}k(!1);}}catch{k(!1);}},X=async e=>{try{if(W&&r.current){if(P?.(e),o.current){let a=await e.arrayBuffer(),s=o.current.encodeBuffer(new Int16Array(a)),c=new Blob([s],{type:"audio/mpeg"});d.current.push(c);}if(await r.current.getState()==="recording"){let a=new Blob(d.current,{type:"audio/mpeg"});if(typeof f=="function"){let s=await f(a);s.text&&m(c=>({...c,text:s.text}));}else {let s=new File([a],"speech.mp3",{type:"audio/mpeg"}),c=await H(s);c&&m(x=>({...x,text:c}));}}}}catch{}},H=reactHooksAsync.useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),h==="transcriptions"&&t.append("language",u?.language??"en"),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let a={};a["Content-Type"]="multipart/form-data",g&&(a.Authorization=`Bearer ${g}`);let{default:s}=await import('axios');return (await s.post(chunkMMJMXXC7_cjs.b+h,t,{headers:a})).data.text},[g,h,u]);return {recording:q,speaking:K,spokeAtLeastOnce:b,transcribing:L,transcript:I,pauseRecording:j,startRecording:$,stopRecording:z}};

exports.a = ue;
//# sourceMappingURL=out.js.map
//# sourceMappingURL=chunk-MFLSJI25.cjs.map