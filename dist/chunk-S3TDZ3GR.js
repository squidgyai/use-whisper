import { b } from './chunk-YMIPE5DI.js';
import { useEffectAsync, useMemoAsync } from '@chengsokdara/react-hooks-async';
import { useRef, useState, useEffect } from 'react';

var te={apiKey:"",autoStart:!1,autoTranscribe:!0,mode:"transcriptions",nonStop:!1,removeSilence:!1,stopTimeout:5e3,streaming:!1,timeSlice:1e3,onDataAvailable:void 0,onTranscribe:void 0},ne={stop:void 0},oe={blob:void 0,text:void 0},ue=F=>{let{apiKey:g,autoStart:C,autoTranscribe:W,mode:h,nonStop:M,removeSilence:ae,stopTimeout:O,streaming:S,timeSlice:P,whisperConfig:u,onDataAvailable:q,onTranscribe:f}={...te,...F};if(!g&&!f)throw new Error("apiKey is required if onTranscribe is not provided");let d=useRef([]),o=useRef(),i=useRef(),r=useRef(),n=useRef(),l=useRef(ne),[K,T]=useState(!1),[L,k]=useState(!1),b$1=useRef(!1),[I,R]=useState(!1),[$,m]=useState(oe),U=new AudioContext;useEffect(()=>()=>{d.current&&(d.current=[]),o.current&&(o.current.flush(),o.current=void 0),r.current&&(r.current.destroy(),r.current=void 0),w("stop"),i.current&&(i.current.off("speaking",A),i.current.off("stopped_speaking",x)),n.current&&(n.current.getTracks().forEach(e=>e.stop()),n.current=void 0);},[]),useEffectAsync(async()=>{C&&await B();},[C]);let j=async()=>{await B();},z=async()=>{await Q();},G=async()=>{await E();},B=async()=>{try{if(n.current||await J(),n.current){if(!r.current){let{default:{RecordRTCPromisesHandler:t,StereoAudioRecorder:a}}=await import('recordrtc'),s={mimeType:"audio/wav",numberOfAudioChannels:1,recorderType:a,sampleRate:U.sampleRate,timeSlice:S?P:void 0,type:"audio",ondataavailable:W&&S?Y:void 0};r.current=new t(n.current,s);}if(!o.current){let{Mp3Encoder:t}=await import('lamejs');o.current=new t(1,U.sampleRate,96);}let e=await r.current.getState();(e==="inactive"||e==="stopped")&&await r.current.startRecording(),e==="paused"&&await r.current.resumeRecording(),T(!0);}}catch{}},J=async()=>{try{if(n.current&&n.current.getTracks().forEach(e=>e.stop()),n.current=await navigator.mediaDevices.getUserMedia({audio:!0}),!i.current){let{default:e}=await import('hark');i.current=e(n.current,{interval:100,play:!1}),i.current.on("speaking",A),i.current.on("stopped_speaking",x);}}catch{}},N=e=>{l.current[e]||(l.current[e]=setTimeout(E,O));},A=()=>{k(!0),b$1.current=!0,w("stop");},x=()=>{k(!1),M&&b$1.current&&N("stop");},Q=async()=>{try{r.current&&(await r.current.getState()==="recording"&&await r.current.pauseRecording(),w("stop"),T(!1));}catch{}},E=async()=>{try{if(r.current){let e=await r.current.getState();if((e==="recording"||e==="paused")&&await r.current.stopRecording(),V(),w("stop"),T(!1),b$1.current=!1,W)await X();else {let t=await r.current.getBlob();m({blob:t});}await r.current.destroy(),d.current=[],o.current&&(o.current.flush(),o.current=void 0),r.current=void 0;}}catch{}},V=()=>{i.current&&(k(!1),i.current.off("speaking",A),i.current.off("stopped_speaking",x),i.current=void 0),n.current&&(n.current.getTracks().forEach(e=>e.stop()),n.current=void 0);},w=e=>{l.current[e]&&(clearTimeout(l.current[e]),l.current[e]=void 0);},X=async()=>{try{if(o.current&&r.current&&await r.current.getState()==="stopped"){R(!0);let t=await r.current.getBlob(),a=await t.arrayBuffer(),s=o.current.encodeBuffer(new Int16Array(a));if(t=new Blob([s],{type:"audio/mpeg"}),typeof f=="function"){let c=await f(t);m(c);}else {let c=new File([t],"speech.mp3",{type:"audio/mpeg"}),v=await H(c);m({blob:t,text:v});}R(!1);}}catch{R(!1);}},Y=async e=>{try{if(S&&r.current){if(q?.(e),o.current){let a=await e.arrayBuffer(),s=o.current.encodeBuffer(new Int16Array(a)),c=new Blob([s],{type:"audio/mpeg"});d.current.push(c);}if(await r.current.getState()==="recording"){let a=new Blob(d.current,{type:"audio/mpeg"});if(typeof f=="function"){let s=await f(a);s.text&&m(c=>({...c,text:s.text}));}else {let s=new File([a],"speech.mp3",{type:"audio/mpeg"}),c=await H(s);c&&m(v=>({...v,text:c}));}}}}catch{}},H=useMemoAsync(async e=>{let t=new FormData;t.append("file",e),t.append("model","whisper-1"),h==="transcriptions"&&t.append("language",u?.language??"en"),u?.prompt&&t.append("prompt",u.prompt),u?.response_format&&t.append("response_format",u.response_format),u?.temperature&&t.append("temperature",`${u.temperature}`);let a={};a["Content-Type"]="multipart/form-data",g&&(a.Authorization=`Bearer ${g}`);let{default:s}=await import('axios');return (await s.post(b+h,t,{headers:a})).data.text},[g,h,u]);return {recording:K,speaking:L,spokeAtLeastOnce:b$1,transcribing:I,transcript:$,pauseRecording:z,startRecording:j,stopRecording:G}};

export { ue as a };
//# sourceMappingURL=out.js.map
//# sourceMappingURL=chunk-S3TDZ3GR.js.map